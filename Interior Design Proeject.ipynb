{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"19dzyxmc5FEwdscJeut0M5dplX38DFeXx","authorship_tag":"ABX9TyN52g9rxFzRdWfTChKMABFu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a733d598f85740f5b45d0ed7befdb560":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b84eed7a55434dc18ea90f366cdcd21a","IPY_MODEL_416ba873bec04551b827d9bc375d4426","IPY_MODEL_59fb11d3f3764a188e05500ee1ecff39"],"layout":"IPY_MODEL_dbaf3b1a427844af81b56f237fb190f8"}},"b84eed7a55434dc18ea90f366cdcd21a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efb38e642ad34e9ebeb934cceb86fce0","placeholder":"​","style":"IPY_MODEL_f5d83904e11445089850bad067e7bf55","value":"Loading pipeline components...: 100%"}},"416ba873bec04551b827d9bc375d4426":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e5b07bddbe142ec908467cfa3c3cb08","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eed3cedcef714884b6ad1ea78bad167e","value":7}},"59fb11d3f3764a188e05500ee1ecff39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5240351d41ee4dde93c0f528800195a9","placeholder":"​","style":"IPY_MODEL_c8cf30c7cc9d40fa97570097e934c236","value":" 7/7 [00:18&lt;00:00,  2.24s/it]"}},"dbaf3b1a427844af81b56f237fb190f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efb38e642ad34e9ebeb934cceb86fce0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5d83904e11445089850bad067e7bf55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e5b07bddbe142ec908467cfa3c3cb08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed3cedcef714884b6ad1ea78bad167e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5240351d41ee4dde93c0f528800195a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8cf30c7cc9d40fa97570097e934c236":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aebffdbba5324c86812d70f352d4e858":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e29476125914cb3a0e5aa56b9f64e33","IPY_MODEL_1bb7461152d440ddba7f9cf7fd2a8392","IPY_MODEL_2f26d4208517497c92e3a61f16a53c9c"],"layout":"IPY_MODEL_7c20fa41ed9e4e2e8b33f1ab98261559"}},"5e29476125914cb3a0e5aa56b9f64e33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baa6d0049e3b440e83e686d5931d1639","placeholder":"​","style":"IPY_MODEL_b161cc2939cf457198b5ead4011fa9fd","value":"Loading pipeline components...: 100%"}},"1bb7461152d440ddba7f9cf7fd2a8392":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a54adea02bb546299087055cf6480a68","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c27910b463184443ab46cdd9904ae535","value":7}},"2f26d4208517497c92e3a61f16a53c9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e3845a0ee22414cb93528bc49c77aa2","placeholder":"​","style":"IPY_MODEL_836d7a29f5bd4983baa5cb70651736cb","value":" 7/7 [00:01&lt;00:00,  3.82it/s]"}},"7c20fa41ed9e4e2e8b33f1ab98261559":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baa6d0049e3b440e83e686d5931d1639":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b161cc2939cf457198b5ead4011fa9fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a54adea02bb546299087055cf6480a68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c27910b463184443ab46cdd9904ae535":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e3845a0ee22414cb93528bc49c77aa2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"836d7a29f5bd4983baa5cb70651736cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c67a1459d1cb487e8c6e0c941fa2b7db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_294bb07e81974b35922ff62c422d7b05","IPY_MODEL_a001f4588e1f4bcf8a0f0c1e0c4a9814","IPY_MODEL_3f277120ccce4d0fb4357c20e10d2c4f"],"layout":"IPY_MODEL_e7127823b33442f190469ba70caf584d"}},"294bb07e81974b35922ff62c422d7b05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afa66bc7739b449cb32d770749ac1802","placeholder":"​","style":"IPY_MODEL_23165559d7e44deb82e558d515053dc0","value":"100%"}},"a001f4588e1f4bcf8a0f0c1e0c4a9814":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ffd02006fb648b2bbce11f0919d87d2","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e023b920cbae473598dca4cef96bf6e9","value":50}},"3f277120ccce4d0fb4357c20e10d2c4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd82fafb7d0944ef977c27ba8f676de0","placeholder":"​","style":"IPY_MODEL_b69771876a564045928ffb1606e0b221","value":" 50/50 [00:08&lt;00:00,  6.16it/s]"}},"e7127823b33442f190469ba70caf584d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afa66bc7739b449cb32d770749ac1802":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23165559d7e44deb82e558d515053dc0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ffd02006fb648b2bbce11f0919d87d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e023b920cbae473598dca4cef96bf6e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd82fafb7d0944ef977c27ba8f676de0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b69771876a564045928ffb1606e0b221":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a733d598f85740f5b45d0ed7befdb560","b84eed7a55434dc18ea90f366cdcd21a","416ba873bec04551b827d9bc375d4426","59fb11d3f3764a188e05500ee1ecff39","dbaf3b1a427844af81b56f237fb190f8","efb38e642ad34e9ebeb934cceb86fce0","f5d83904e11445089850bad067e7bf55","8e5b07bddbe142ec908467cfa3c3cb08","eed3cedcef714884b6ad1ea78bad167e","5240351d41ee4dde93c0f528800195a9","c8cf30c7cc9d40fa97570097e934c236"]},"id":"LHWc32_F6NiK","executionInfo":{"status":"ok","timestamp":1737202207969,"user_tz":-330,"elapsed":1500576,"user":{"displayName":"sumit sartale","userId":"13643088278365937465"}},"outputId":"26618358-478b-4326-bf9b-a126a28dcf1a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a733d598f85740f5b45d0ed7befdb560"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-c330fec0e4fc>:96: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler()\n","<ipython-input-2-c330fec0e4fc>:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n"]},{"output_type":"stream","name":"stdout","text":["Starting epoch 1/5\n","Epoch 1, Step 0, Loss: 132.57196044921875\n","Epoch 1, Step 1, Loss: 121.55836486816406\n","Epoch 1, Step 2, Loss: 120.37560272216797\n","Error at Step 3: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 4, Loss: 108.87981414794922\n","Epoch 1, Step 5, Loss: 113.4191665649414\n","Epoch 1, Step 6, Loss: 115.22425842285156\n","Error at Step 7: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 8, Loss: 87.11736297607422\n","Epoch 1, Step 9, Loss: 101.39501190185547\n","Epoch 1, Step 10, Loss: 143.4488525390625\n","Error at Step 11: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 12, Loss: 106.17118072509766\n","Epoch 1, Step 13, Loss: 119.50501251220703\n","Epoch 1, Step 14, Loss: 113.45347595214844\n","Error at Step 15: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 16, Loss: 248.5630645751953\n","Epoch 1, Step 17, Loss: 104.7156753540039\n","Epoch 1, Step 18, Loss: 159.15570068359375\n","Error at Step 19: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 20, Loss: 120.43010711669922\n","Epoch 1, Step 21, Loss: 96.99358367919922\n","Epoch 1, Step 22, Loss: 128.90476989746094\n","Error at Step 23: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 24, Loss: 104.55911254882812\n","Epoch 1, Step 25, Loss: 164.58702087402344\n","Epoch 1, Step 26, Loss: 137.93154907226562\n","Error at Step 27: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 28, Loss: 87.99635314941406\n","Epoch 1, Step 29, Loss: 84.8945541381836\n","Epoch 1, Step 30, Loss: 156.228515625\n","Error at Step 31: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 32, Loss: 93.89115905761719\n","Epoch 1, Step 33, Loss: 131.33880615234375\n","Epoch 1, Step 34, Loss: 98.95356750488281\n","Error at Step 35: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 36, Loss: 136.71099853515625\n","Epoch 1, Step 37, Loss: 80.53175354003906\n","Epoch 1, Step 38, Loss: 100.1176986694336\n","Error at Step 39: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 40, Loss: 129.92535400390625\n","Epoch 1, Step 41, Loss: 113.24047088623047\n","Epoch 1, Step 42, Loss: 124.28450775146484\n","Error at Step 43: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 44, Loss: 131.97738647460938\n","Epoch 1, Step 45, Loss: 114.1296615600586\n","Epoch 1, Step 46, Loss: 139.54437255859375\n","Error at Step 47: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 48, Loss: 135.55438232421875\n","Epoch 1, Step 49, Loss: 145.65318298339844\n","Epoch 1, Step 50, Loss: 117.78166961669922\n","Error at Step 51: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 52, Loss: 141.50509643554688\n","Epoch 1, Step 53, Loss: 105.36185455322266\n","Epoch 1, Step 54, Loss: 158.4582977294922\n","Error at Step 55: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 56, Loss: 146.00204467773438\n","Epoch 1, Step 57, Loss: 104.10444641113281\n","Epoch 1, Step 58, Loss: 128.00253295898438\n","Error at Step 59: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 60, Loss: 92.29259490966797\n","Epoch 1, Step 61, Loss: 138.1265411376953\n","Epoch 1, Step 62, Loss: 142.87738037109375\n","Error at Step 63: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 64, Loss: 148.21632385253906\n","Epoch 1, Step 65, Loss: 106.77043914794922\n","Epoch 1, Step 66, Loss: 100.35823822021484\n","Error at Step 67: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 68, Loss: 101.85343170166016\n","Epoch 1, Step 69, Loss: 120.06433868408203\n","Epoch 1, Step 70, Loss: 158.93138122558594\n","Error at Step 71: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 72, Loss: 89.47439575195312\n","Epoch 1, Step 73, Loss: 197.3069610595703\n","Epoch 1, Step 74, Loss: 121.44017791748047\n","Error at Step 75: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 76, Loss: 102.38246154785156\n","Epoch 1, Step 77, Loss: 152.9790802001953\n","Epoch 1, Step 78, Loss: 123.92204284667969\n","Error at Step 79: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 80, Loss: 231.6454315185547\n","Epoch 1, Step 81, Loss: 196.899169921875\n","Epoch 1, Step 82, Loss: 108.43502044677734\n","Error at Step 83: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 84, Loss: 132.55935668945312\n","Epoch 1, Step 85, Loss: 98.30604553222656\n","Epoch 1, Step 86, Loss: 169.62429809570312\n","Error at Step 87: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 88, Loss: 125.9347915649414\n","Epoch 1, Step 89, Loss: 129.82180786132812\n","Epoch 1, Step 90, Loss: 131.94935607910156\n","Error at Step 91: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 92, Loss: 135.60015869140625\n","Epoch 1, Step 93, Loss: 102.98991394042969\n","Epoch 1, Step 94, Loss: 143.21934509277344\n","Error at Step 95: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 96, Loss: 119.07158660888672\n","Epoch 1, Step 97, Loss: 114.32205963134766\n","Epoch 1, Step 98, Loss: 133.96627807617188\n","Error at Step 99: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 100, Loss: 128.5599365234375\n","Epoch 1, Step 101, Loss: 107.92504119873047\n","Epoch 1, Step 102, Loss: 101.90623474121094\n","Error at Step 103: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 104, Loss: 102.10413360595703\n","Epoch 1, Step 105, Loss: 165.59703063964844\n","Epoch 1, Step 106, Loss: 101.10929107666016\n","Error at Step 107: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 108, Loss: 147.9788055419922\n","Epoch 1, Step 109, Loss: 133.4117431640625\n","Epoch 1, Step 110, Loss: 229.4114227294922\n","Error at Step 111: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 112, Loss: 148.78350830078125\n","Epoch 1, Step 113, Loss: 133.7854766845703\n","Epoch 1, Step 114, Loss: 124.41234588623047\n","Error at Step 115: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 116, Loss: 108.4915542602539\n","Epoch 1, Step 117, Loss: 147.90281677246094\n","Epoch 1, Step 118, Loss: 141.2896270751953\n","Error at Step 119: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 120, Loss: 96.86360931396484\n","Epoch 1, Step 121, Loss: 147.7445068359375\n","Epoch 1, Step 122, Loss: 79.36140441894531\n","Error at Step 123: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 124, Loss: 128.1339874267578\n","Epoch 1, Step 125, Loss: 104.6019515991211\n","Epoch 1, Step 126, Loss: 114.18801879882812\n","Error at Step 127: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 128, Loss: 210.30075073242188\n","Epoch 1, Step 129, Loss: 159.60757446289062\n","Epoch 1, Step 130, Loss: 127.80799102783203\n","Error at Step 131: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 132, Loss: 113.6324691772461\n","Epoch 1, Step 133, Loss: 93.93252563476562\n","Epoch 1, Step 134, Loss: 161.4977569580078\n","Error at Step 135: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 136, Loss: 169.12344360351562\n","Epoch 1, Step 137, Loss: 97.52932739257812\n","Epoch 1, Step 138, Loss: 108.03064727783203\n","Error at Step 139: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 140, Loss: 174.45480346679688\n","Epoch 1, Step 141, Loss: 102.23245239257812\n","Epoch 1, Step 142, Loss: 115.98588562011719\n","Error at Step 143: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 144, Loss: 98.13428497314453\n","Epoch 1, Step 145, Loss: 168.15916442871094\n","Epoch 1, Step 146, Loss: 99.79789733886719\n","Error at Step 147: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 148, Loss: 128.94151306152344\n","Epoch 1, Step 149, Loss: 102.68647766113281\n","Epoch 1, Step 150, Loss: 131.0596466064453\n","Error at Step 151: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 152, Loss: 119.01448822021484\n","Epoch 1, Step 153, Loss: 75.0699234008789\n","Epoch 1, Step 154, Loss: 120.81563568115234\n","Error at Step 155: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 156, Loss: 103.79196166992188\n","Epoch 1, Step 157, Loss: 101.88130950927734\n","Epoch 1, Step 158, Loss: 136.70022583007812\n","Error at Step 159: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 160, Loss: 117.1148452758789\n","Epoch 1, Step 161, Loss: 127.55525207519531\n","Epoch 1, Step 162, Loss: 114.70954895019531\n","Error at Step 163: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 164, Loss: 98.07701110839844\n","Epoch 1, Step 165, Loss: 84.50367736816406\n","Epoch 1, Step 166, Loss: 120.1166000366211\n","Error at Step 167: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 168, Loss: 97.2514877319336\n","Epoch 1, Step 169, Loss: 172.540771484375\n","Epoch 1, Step 170, Loss: 104.24930572509766\n","Error at Step 171: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 172, Loss: 109.02168273925781\n","Epoch 1, Step 173, Loss: 97.7140884399414\n","Epoch 1, Step 174, Loss: 128.5343475341797\n","Error at Step 175: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 176, Loss: 116.07225036621094\n","Epoch 1, Step 177, Loss: 217.69882202148438\n","Epoch 1, Step 178, Loss: 142.90316772460938\n","Error at Step 179: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 180, Loss: 190.7677459716797\n","Epoch 1, Step 181, Loss: 170.30567932128906\n","Epoch 1, Step 182, Loss: 152.0731964111328\n","Error at Step 183: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 184, Loss: 170.4454803466797\n","Epoch 1, Step 185, Loss: 203.0391845703125\n","Epoch 1, Step 186, Loss: 165.6712646484375\n","Error at Step 187: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 188, Loss: 101.42668151855469\n","Epoch 1, Step 189, Loss: 149.20095825195312\n","Epoch 1, Step 190, Loss: 130.53749084472656\n","Error at Step 191: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 192, Loss: 102.41448974609375\n","Epoch 1, Step 193, Loss: 205.7230987548828\n","Epoch 1, Step 194, Loss: 124.84214782714844\n","Error at Step 195: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 196, Loss: 122.62071990966797\n","Epoch 1, Step 197, Loss: 118.0247573852539\n","Epoch 1, Step 198, Loss: 115.46769714355469\n","Error at Step 199: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 200, Loss: 111.90898895263672\n","Epoch 1, Step 201, Loss: 134.7585906982422\n","Epoch 1, Step 202, Loss: 95.55584716796875\n","Error at Step 203: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 204, Loss: 93.65166473388672\n","Epoch 1, Step 205, Loss: 124.75001525878906\n","Epoch 1, Step 206, Loss: 117.6753158569336\n","Error at Step 207: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 208, Loss: 110.613037109375\n","Epoch 1, Step 209, Loss: 138.66590881347656\n","Epoch 1, Step 210, Loss: 155.90817260742188\n","Error at Step 211: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 212, Loss: 105.88512420654297\n","Epoch 1, Step 213, Loss: 106.47805786132812\n","Epoch 1, Step 214, Loss: 152.1531982421875\n","Error at Step 215: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 216, Loss: 131.32371520996094\n","Epoch 1, Step 217, Loss: 105.81010437011719\n","Epoch 1, Step 218, Loss: 117.94100189208984\n","Error at Step 219: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 220, Loss: 97.09468841552734\n","Epoch 1, Step 221, Loss: 125.7117691040039\n","Epoch 1, Step 222, Loss: 115.532958984375\n","Error at Step 223: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 224, Loss: 114.72412872314453\n","Epoch 1, Step 225, Loss: 140.22836303710938\n","Epoch 1, Step 226, Loss: 146.11746215820312\n","Error at Step 227: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 228, Loss: 108.53010559082031\n","Epoch 1, Step 229, Loss: 185.77212524414062\n","Epoch 1, Step 230, Loss: 111.30414581298828\n","Error at Step 231: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 232, Loss: 144.36781311035156\n","Epoch 1, Step 233, Loss: 108.56058502197266\n","Epoch 1, Step 234, Loss: 117.11974334716797\n","Error at Step 235: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 236, Loss: 211.79563903808594\n","Epoch 1, Step 237, Loss: 105.23871612548828\n","Epoch 1, Step 238, Loss: 214.84129333496094\n","Error at Step 239: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 240, Loss: 137.8788299560547\n","Epoch 1, Step 241, Loss: 199.2505645751953\n","Epoch 1, Step 242, Loss: 157.27940368652344\n","Error at Step 243: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 244, Loss: 148.41041564941406\n","Epoch 1, Step 245, Loss: 129.32083129882812\n","Epoch 1, Step 246, Loss: 121.82981872558594\n","Error at Step 247: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 248, Loss: 164.02183532714844\n","Epoch 1, Step 249, Loss: 119.99298095703125\n","Epoch 1, Step 250, Loss: 90.39775085449219\n","Error at Step 251: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 252, Loss: 221.9869384765625\n","Epoch 1, Step 253, Loss: 118.45812225341797\n","Epoch 1, Step 254, Loss: 99.48825073242188\n","Error at Step 255: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 256, Loss: 114.31998443603516\n","Epoch 1, Step 257, Loss: 116.23304748535156\n","Epoch 1, Step 258, Loss: 156.41490173339844\n","Error at Step 259: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 260, Loss: 107.13006591796875\n","Epoch 1, Step 261, Loss: 100.05329132080078\n","Epoch 1, Step 262, Loss: 155.7861785888672\n","Error at Step 263: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 264, Loss: 126.0785140991211\n","Epoch 1, Step 265, Loss: 115.85773468017578\n","Epoch 1, Step 266, Loss: 115.65037536621094\n","Error at Step 267: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 268, Loss: 153.7499542236328\n","Epoch 1, Step 269, Loss: 154.26260375976562\n","Epoch 1, Step 270, Loss: 155.8551025390625\n","Error at Step 271: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 272, Loss: 102.13179779052734\n","Epoch 1, Step 273, Loss: 134.43264770507812\n","Epoch 1, Step 274, Loss: 92.19709014892578\n","Error at Step 275: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 276, Loss: 151.1181182861328\n","Epoch 1, Step 277, Loss: 124.12042999267578\n","Epoch 1, Step 278, Loss: 123.75548553466797\n","Error at Step 279: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 280, Loss: 112.53117370605469\n","Epoch 1, Step 281, Loss: 142.33209228515625\n","Epoch 1, Step 282, Loss: 90.29579162597656\n","Error at Step 283: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 284, Loss: 137.48468017578125\n","Epoch 1, Step 285, Loss: 92.20835876464844\n","Epoch 1, Step 286, Loss: 298.32745361328125\n","Error at Step 287: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 288, Loss: 128.4302215576172\n","Epoch 1, Step 289, Loss: 114.62702941894531\n","Epoch 1, Step 290, Loss: 123.6054458618164\n","Error at Step 291: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 292, Loss: 125.84278869628906\n","Epoch 1, Step 293, Loss: 108.93275451660156\n","Epoch 1, Step 294, Loss: 144.052978515625\n","Error at Step 295: Attempting to unscale FP16 gradients.\n","Epoch 1, Step 296, Loss: 99.60309600830078\n","Epoch 1, Step 297, Loss: 117.56834411621094\n","Epoch 1, Step 298, Loss: 90.28233337402344\n","Error at Step 299: Attempting to unscale FP16 gradients.\n","Starting epoch 2/5\n","Epoch 2, Step 0, Loss: 140.35174560546875\n","Epoch 2, Step 1, Loss: 146.2141876220703\n","Epoch 2, Step 2, Loss: 111.46388244628906\n","Error at Step 3: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 4, Loss: 108.02099609375\n","Epoch 2, Step 5, Loss: 99.21686553955078\n","Epoch 2, Step 6, Loss: 115.95398712158203\n","Error at Step 7: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 8, Loss: 115.87971496582031\n","Epoch 2, Step 9, Loss: 104.16525268554688\n","Epoch 2, Step 10, Loss: 106.7734146118164\n","Error at Step 11: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 12, Loss: 114.17919921875\n","Epoch 2, Step 13, Loss: 108.57243347167969\n","Epoch 2, Step 14, Loss: 133.35060119628906\n","Error at Step 15: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 16, Loss: 117.6438217163086\n","Epoch 2, Step 17, Loss: 115.61239624023438\n","Epoch 2, Step 18, Loss: 113.97874450683594\n","Error at Step 19: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 20, Loss: 117.02001953125\n","Epoch 2, Step 21, Loss: 164.61325073242188\n","Epoch 2, Step 22, Loss: 186.07969665527344\n","Error at Step 23: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 24, Loss: 132.64236450195312\n","Epoch 2, Step 25, Loss: 153.7173309326172\n","Epoch 2, Step 26, Loss: 119.67984008789062\n","Error at Step 27: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 28, Loss: 124.47644805908203\n","Epoch 2, Step 29, Loss: 115.31050872802734\n","Epoch 2, Step 30, Loss: 101.54346466064453\n","Error at Step 31: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 32, Loss: 107.92486572265625\n","Epoch 2, Step 33, Loss: 97.30794525146484\n","Epoch 2, Step 34, Loss: 96.67212677001953\n","Error at Step 35: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 36, Loss: 157.7550506591797\n","Epoch 2, Step 37, Loss: 108.86563110351562\n","Epoch 2, Step 38, Loss: 123.90100860595703\n","Error at Step 39: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 40, Loss: 148.3986053466797\n","Epoch 2, Step 41, Loss: 231.50283813476562\n","Epoch 2, Step 42, Loss: 97.97013092041016\n","Error at Step 43: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 44, Loss: 113.96125030517578\n","Epoch 2, Step 45, Loss: 119.58592224121094\n","Epoch 2, Step 46, Loss: 104.75971984863281\n","Error at Step 47: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 48, Loss: 117.98461151123047\n","Epoch 2, Step 49, Loss: 114.80374908447266\n","Epoch 2, Step 50, Loss: 127.79489135742188\n","Error at Step 51: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 52, Loss: 130.61300659179688\n","Epoch 2, Step 53, Loss: 102.0406494140625\n","Epoch 2, Step 54, Loss: 133.85740661621094\n","Error at Step 55: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 56, Loss: 135.47171020507812\n","Epoch 2, Step 57, Loss: 121.50584411621094\n","Epoch 2, Step 58, Loss: 123.6556396484375\n","Error at Step 59: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 60, Loss: 133.8724365234375\n","Epoch 2, Step 61, Loss: 124.55223846435547\n","Epoch 2, Step 62, Loss: 115.02782440185547\n","Error at Step 63: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 64, Loss: 210.29917907714844\n","Epoch 2, Step 65, Loss: 165.90951538085938\n","Epoch 2, Step 66, Loss: 117.67070007324219\n","Error at Step 67: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 68, Loss: 143.14320373535156\n","Epoch 2, Step 69, Loss: 168.86404418945312\n","Epoch 2, Step 70, Loss: 141.31857299804688\n","Error at Step 71: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 72, Loss: 125.87549591064453\n","Epoch 2, Step 73, Loss: 92.04220581054688\n","Epoch 2, Step 74, Loss: 118.85643768310547\n","Error at Step 75: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 76, Loss: 134.95999145507812\n","Epoch 2, Step 77, Loss: 106.65213012695312\n","Epoch 2, Step 78, Loss: 102.00163269042969\n","Error at Step 79: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 80, Loss: 119.84269714355469\n","Epoch 2, Step 81, Loss: 142.8761444091797\n","Epoch 2, Step 82, Loss: 105.17913055419922\n","Error at Step 83: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 84, Loss: 95.45185089111328\n","Epoch 2, Step 85, Loss: 131.02792358398438\n","Epoch 2, Step 86, Loss: 97.68236541748047\n","Error at Step 87: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 88, Loss: 102.5673599243164\n","Epoch 2, Step 89, Loss: 98.9177017211914\n","Epoch 2, Step 90, Loss: 154.41116333007812\n","Error at Step 91: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 92, Loss: 131.9657440185547\n","Epoch 2, Step 93, Loss: 115.55441284179688\n","Epoch 2, Step 94, Loss: 139.6037139892578\n","Error at Step 95: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 96, Loss: 144.55459594726562\n","Epoch 2, Step 97, Loss: 148.20680236816406\n","Epoch 2, Step 98, Loss: 93.80048370361328\n","Error at Step 99: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 100, Loss: 156.43446350097656\n","Epoch 2, Step 101, Loss: 107.38970947265625\n","Epoch 2, Step 102, Loss: 97.16741180419922\n","Error at Step 103: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 104, Loss: 148.1228790283203\n","Epoch 2, Step 105, Loss: 170.5947265625\n","Epoch 2, Step 106, Loss: 124.92619323730469\n","Error at Step 107: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 108, Loss: 100.01280975341797\n","Epoch 2, Step 109, Loss: 128.98634338378906\n","Epoch 2, Step 110, Loss: 124.35889434814453\n","Error at Step 111: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 112, Loss: 108.9203872680664\n","Epoch 2, Step 113, Loss: 88.42058563232422\n","Epoch 2, Step 114, Loss: 142.2036590576172\n","Error at Step 115: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 116, Loss: 129.04037475585938\n","Epoch 2, Step 117, Loss: 106.00342559814453\n","Epoch 2, Step 118, Loss: 103.72866821289062\n","Error at Step 119: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 120, Loss: 88.90303039550781\n","Epoch 2, Step 121, Loss: 127.44734191894531\n","Epoch 2, Step 122, Loss: 113.439453125\n","Error at Step 123: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 124, Loss: 102.69233703613281\n","Epoch 2, Step 125, Loss: 104.22596740722656\n","Epoch 2, Step 126, Loss: 152.21961975097656\n","Error at Step 127: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 128, Loss: 135.9645233154297\n","Epoch 2, Step 129, Loss: 118.28531646728516\n","Epoch 2, Step 130, Loss: 85.01762390136719\n","Error at Step 131: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 132, Loss: 93.81803894042969\n","Epoch 2, Step 133, Loss: 114.7267074584961\n","Epoch 2, Step 134, Loss: 133.5882110595703\n","Error at Step 135: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 136, Loss: 119.83984375\n","Epoch 2, Step 137, Loss: 133.68670654296875\n","Epoch 2, Step 138, Loss: 172.63351440429688\n","Error at Step 139: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 140, Loss: 148.1095428466797\n","Epoch 2, Step 141, Loss: 156.4725341796875\n","Epoch 2, Step 142, Loss: 174.4920654296875\n","Error at Step 143: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 144, Loss: 136.77890014648438\n","Epoch 2, Step 145, Loss: 95.87061309814453\n","Epoch 2, Step 146, Loss: 121.626220703125\n","Error at Step 147: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 148, Loss: 106.24584197998047\n","Epoch 2, Step 149, Loss: 118.5267562866211\n","Epoch 2, Step 150, Loss: 102.335693359375\n","Error at Step 151: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 152, Loss: 128.10484313964844\n","Epoch 2, Step 153, Loss: 103.87130737304688\n","Epoch 2, Step 154, Loss: 169.6962127685547\n","Error at Step 155: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 156, Loss: 129.700439453125\n","Epoch 2, Step 157, Loss: 145.21934509277344\n","Epoch 2, Step 158, Loss: 155.8112030029297\n","Error at Step 159: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 160, Loss: 113.46842193603516\n","Epoch 2, Step 161, Loss: 158.99339294433594\n","Epoch 2, Step 162, Loss: 135.69180297851562\n","Error at Step 163: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 164, Loss: 102.13987731933594\n","Epoch 2, Step 165, Loss: 231.71795654296875\n","Epoch 2, Step 166, Loss: 102.33179473876953\n","Error at Step 167: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 168, Loss: 168.2743377685547\n","Epoch 2, Step 169, Loss: 108.21875762939453\n","Epoch 2, Step 170, Loss: 93.74149322509766\n","Error at Step 171: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 172, Loss: 124.84375762939453\n","Epoch 2, Step 173, Loss: 109.02630615234375\n","Epoch 2, Step 174, Loss: 137.91957092285156\n","Error at Step 175: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 176, Loss: 122.62510681152344\n","Epoch 2, Step 177, Loss: 132.0904541015625\n","Epoch 2, Step 178, Loss: 98.1300277709961\n","Error at Step 179: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 180, Loss: 159.12240600585938\n","Epoch 2, Step 181, Loss: 101.88369750976562\n","Epoch 2, Step 182, Loss: 143.20449829101562\n","Error at Step 183: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 184, Loss: 92.11174011230469\n","Epoch 2, Step 185, Loss: 132.1819305419922\n","Epoch 2, Step 186, Loss: 132.82777404785156\n","Error at Step 187: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 188, Loss: 119.58572387695312\n","Epoch 2, Step 189, Loss: 115.88529968261719\n","Epoch 2, Step 190, Loss: 194.21353149414062\n","Error at Step 191: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 192, Loss: 92.31220245361328\n","Epoch 2, Step 193, Loss: 114.3471450805664\n","Epoch 2, Step 194, Loss: 174.27137756347656\n","Error at Step 195: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 196, Loss: 121.4034652709961\n","Epoch 2, Step 197, Loss: 129.3180389404297\n","Epoch 2, Step 198, Loss: 131.2615966796875\n","Error at Step 199: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 200, Loss: 131.05813598632812\n","Epoch 2, Step 201, Loss: 137.5121612548828\n","Epoch 2, Step 202, Loss: 191.02745056152344\n","Error at Step 203: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 204, Loss: 83.6933822631836\n","Epoch 2, Step 205, Loss: 108.49201202392578\n","Epoch 2, Step 206, Loss: 87.8010482788086\n","Error at Step 207: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 208, Loss: 205.83163452148438\n","Epoch 2, Step 209, Loss: 98.23226928710938\n","Epoch 2, Step 210, Loss: 165.51669311523438\n","Error at Step 211: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 212, Loss: 117.98723602294922\n","Epoch 2, Step 213, Loss: 159.77005004882812\n","Epoch 2, Step 214, Loss: 190.6803741455078\n","Error at Step 215: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 216, Loss: 103.09664154052734\n","Epoch 2, Step 217, Loss: 104.70726013183594\n","Epoch 2, Step 218, Loss: 196.70291137695312\n","Error at Step 219: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 220, Loss: 132.5980682373047\n","Epoch 2, Step 221, Loss: 170.59835815429688\n","Epoch 2, Step 222, Loss: 114.32652282714844\n","Error at Step 223: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 224, Loss: 145.58489990234375\n","Epoch 2, Step 225, Loss: 148.8390655517578\n","Epoch 2, Step 226, Loss: 133.63397216796875\n","Error at Step 227: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 228, Loss: 150.1728515625\n","Epoch 2, Step 229, Loss: 97.626708984375\n","Epoch 2, Step 230, Loss: 99.66947937011719\n","Error at Step 231: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 232, Loss: 115.64190673828125\n","Epoch 2, Step 233, Loss: 113.19910430908203\n","Epoch 2, Step 234, Loss: 83.2298355102539\n","Error at Step 235: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 236, Loss: 126.08848571777344\n","Epoch 2, Step 237, Loss: 121.73231506347656\n","Epoch 2, Step 238, Loss: 186.9352264404297\n","Error at Step 239: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 240, Loss: 108.60809326171875\n","Epoch 2, Step 241, Loss: 138.59632873535156\n","Epoch 2, Step 242, Loss: 151.23167419433594\n","Error at Step 243: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 244, Loss: 155.69920349121094\n","Epoch 2, Step 245, Loss: 133.69580078125\n","Epoch 2, Step 246, Loss: 145.49630737304688\n","Error at Step 247: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 248, Loss: 123.84884643554688\n","Epoch 2, Step 249, Loss: 199.3258514404297\n","Epoch 2, Step 250, Loss: 158.1974334716797\n","Error at Step 251: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 252, Loss: 100.29145050048828\n","Epoch 2, Step 253, Loss: 153.09388732910156\n","Epoch 2, Step 254, Loss: 142.90029907226562\n","Error at Step 255: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 256, Loss: 124.3280258178711\n","Epoch 2, Step 257, Loss: 128.36082458496094\n","Epoch 2, Step 258, Loss: 214.934814453125\n","Error at Step 259: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 260, Loss: 168.5665283203125\n","Epoch 2, Step 261, Loss: 298.3233642578125\n","Epoch 2, Step 262, Loss: 143.69976806640625\n","Error at Step 263: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 264, Loss: 221.9801483154297\n","Epoch 2, Step 265, Loss: 141.22286987304688\n","Epoch 2, Step 266, Loss: 84.48684692382812\n","Error at Step 267: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 268, Loss: 152.92791748046875\n","Epoch 2, Step 269, Loss: 120.45623016357422\n","Epoch 2, Step 270, Loss: 203.04580688476562\n","Error at Step 271: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 272, Loss: 172.27435302734375\n","Epoch 2, Step 273, Loss: 211.91831970214844\n","Epoch 2, Step 274, Loss: 128.98095703125\n","Error at Step 275: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 276, Loss: 144.06910705566406\n","Epoch 2, Step 277, Loss: 143.21963500976562\n","Epoch 2, Step 278, Loss: 115.14338684082031\n","Error at Step 279: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 280, Loss: 79.3495101928711\n","Epoch 2, Step 281, Loss: 110.65339660644531\n","Epoch 2, Step 282, Loss: 155.8590087890625\n","Error at Step 283: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 284, Loss: 120.60250091552734\n","Epoch 2, Step 285, Loss: 93.28742218017578\n","Epoch 2, Step 286, Loss: 143.46310424804688\n","Error at Step 287: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 288, Loss: 92.22500610351562\n","Epoch 2, Step 289, Loss: 90.05199432373047\n","Epoch 2, Step 290, Loss: 137.7654266357422\n","Error at Step 291: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 292, Loss: 96.57145690917969\n","Epoch 2, Step 293, Loss: 101.49607849121094\n","Epoch 2, Step 294, Loss: 89.77632141113281\n","Error at Step 295: Attempting to unscale FP16 gradients.\n","Epoch 2, Step 296, Loss: 107.86371612548828\n","Epoch 2, Step 297, Loss: 105.22402954101562\n","Epoch 2, Step 298, Loss: 104.08000946044922\n","Error at Step 299: Attempting to unscale FP16 gradients.\n","Starting epoch 3/5\n","Epoch 3, Step 0, Loss: 124.67816162109375\n","Epoch 3, Step 1, Loss: 161.71038818359375\n","Epoch 3, Step 2, Loss: 148.22804260253906\n","Error at Step 3: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 4, Loss: 143.2618408203125\n","Epoch 3, Step 5, Loss: 142.1515655517578\n","Epoch 3, Step 6, Loss: 124.92794799804688\n","Error at Step 7: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 8, Loss: 152.15565490722656\n","Epoch 3, Step 9, Loss: 98.00470733642578\n","Epoch 3, Step 10, Loss: 97.07181549072266\n","Error at Step 11: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 12, Loss: 90.5599365234375\n","Epoch 3, Step 13, Loss: 114.2673110961914\n","Epoch 3, Step 14, Loss: 131.14743041992188\n","Error at Step 15: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 16, Loss: 146.21615600585938\n","Epoch 3, Step 17, Loss: 115.85986328125\n","Epoch 3, Step 18, Loss: 105.90535736083984\n","Error at Step 19: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 20, Loss: 93.67628479003906\n","Epoch 3, Step 21, Loss: 170.5886688232422\n","Epoch 3, Step 22, Loss: 103.89128112792969\n","Error at Step 23: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 24, Loss: 135.7711181640625\n","Epoch 3, Step 25, Loss: 115.54595184326172\n","Epoch 3, Step 26, Loss: 121.84471130371094\n","Error at Step 27: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 28, Loss: 117.97715759277344\n","Epoch 3, Step 29, Loss: 108.92496490478516\n","Epoch 3, Step 30, Loss: 111.51465606689453\n","Error at Step 31: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 32, Loss: 86.41584014892578\n","Epoch 3, Step 33, Loss: 165.4880828857422\n","Epoch 3, Step 34, Loss: 119.94279479980469\n","Error at Step 35: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 36, Loss: 164.17605590820312\n","Epoch 3, Step 37, Loss: 133.8651580810547\n","Epoch 3, Step 38, Loss: 119.94017028808594\n","Error at Step 39: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 40, Loss: 128.63528442382812\n","Epoch 3, Step 41, Loss: 117.79148864746094\n","Epoch 3, Step 42, Loss: 168.9236602783203\n","Error at Step 43: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 44, Loss: 155.69020080566406\n","Epoch 3, Step 45, Loss: 184.1708984375\n","Epoch 3, Step 46, Loss: 169.70977783203125\n","Error at Step 47: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 48, Loss: 128.46365356445312\n","Epoch 3, Step 49, Loss: 102.02595520019531\n","Epoch 3, Step 50, Loss: 124.11064147949219\n","Error at Step 51: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 52, Loss: 122.74295043945312\n","Epoch 3, Step 53, Loss: 148.54458618164062\n","Epoch 3, Step 54, Loss: 133.57408142089844\n","Error at Step 55: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 56, Loss: 99.8843994140625\n","Epoch 3, Step 57, Loss: 112.87944030761719\n","Epoch 3, Step 58, Loss: 248.58197021484375\n","Error at Step 59: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 60, Loss: 119.84262084960938\n","Epoch 3, Step 61, Loss: 84.68002319335938\n","Epoch 3, Step 62, Loss: 132.60504150390625\n","Error at Step 63: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 64, Loss: 92.04547119140625\n","Epoch 3, Step 65, Loss: 199.54840087890625\n","Epoch 3, Step 66, Loss: 114.22612762451172\n","Error at Step 67: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 68, Loss: 142.90945434570312\n","Epoch 3, Step 69, Loss: 120.09123992919922\n","Epoch 3, Step 70, Loss: 196.7566680908203\n","Error at Step 71: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 72, Loss: 101.00162506103516\n","Epoch 3, Step 73, Loss: 98.2183837890625\n","Epoch 3, Step 74, Loss: 187.06533813476562\n","Error at Step 75: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 76, Loss: 101.53645324707031\n","Epoch 3, Step 77, Loss: 120.61273956298828\n","Epoch 3, Step 78, Loss: 96.73628997802734\n","Error at Step 79: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 80, Loss: 113.50599670410156\n","Epoch 3, Step 81, Loss: 103.63679504394531\n","Epoch 3, Step 82, Loss: 146.2161865234375\n","Error at Step 83: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 84, Loss: 134.85214233398438\n","Epoch 3, Step 85, Loss: 119.25949096679688\n","Epoch 3, Step 86, Loss: 210.40052795410156\n","Error at Step 87: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 88, Loss: 142.99476623535156\n","Epoch 3, Step 89, Loss: 87.01065063476562\n","Epoch 3, Step 90, Loss: 153.7411651611328\n","Error at Step 91: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 92, Loss: 157.2715606689453\n","Epoch 3, Step 93, Loss: 152.86965942382812\n","Epoch 3, Step 94, Loss: 102.12008666992188\n","Error at Step 95: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 96, Loss: 142.91348266601562\n","Epoch 3, Step 97, Loss: 92.26799011230469\n","Epoch 3, Step 98, Loss: 80.33931732177734\n","Error at Step 99: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 100, Loss: 144.3935089111328\n","Epoch 3, Step 101, Loss: 131.3450927734375\n","Epoch 3, Step 102, Loss: 132.6669921875\n","Error at Step 103: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 104, Loss: 298.51007080078125\n","Epoch 3, Step 105, Loss: 106.7265396118164\n","Epoch 3, Step 106, Loss: 109.89839935302734\n","Error at Step 107: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 108, Loss: 134.3468475341797\n","Epoch 3, Step 109, Loss: 139.7265625\n","Epoch 3, Step 110, Loss: 131.1297149658203\n","Error at Step 111: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 112, Loss: 110.75981140136719\n","Epoch 3, Step 113, Loss: 136.67803955078125\n","Epoch 3, Step 114, Loss: 108.5955581665039\n","Error at Step 115: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 116, Loss: 113.9746322631836\n","Epoch 3, Step 117, Loss: 111.25398254394531\n","Epoch 3, Step 118, Loss: 145.04104614257812\n","Error at Step 119: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 120, Loss: 106.21936798095703\n","Epoch 3, Step 121, Loss: 148.8406982421875\n","Epoch 3, Step 122, Loss: 124.54680633544922\n","Error at Step 123: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 124, Loss: 90.11115264892578\n","Epoch 3, Step 125, Loss: 108.38494873046875\n","Epoch 3, Step 126, Loss: 107.73627471923828\n","Error at Step 127: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 128, Loss: 205.77963256835938\n","Epoch 3, Step 129, Loss: 104.77111053466797\n","Epoch 3, Step 130, Loss: 194.35498046875\n","Error at Step 131: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 132, Loss: 114.77143859863281\n","Epoch 3, Step 133, Loss: 96.8486328125\n","Epoch 3, Step 134, Loss: 101.73560333251953\n","Error at Step 135: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 136, Loss: 102.70427703857422\n","Epoch 3, Step 137, Loss: 112.02904510498047\n","Epoch 3, Step 138, Loss: 123.6620101928711\n","Error at Step 139: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 140, Loss: 157.9264373779297\n","Epoch 3, Step 141, Loss: 170.44790649414062\n","Epoch 3, Step 142, Loss: 231.8932342529297\n","Error at Step 143: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 144, Loss: 122.6878890991211\n","Epoch 3, Step 145, Loss: 119.1148681640625\n","Epoch 3, Step 146, Loss: 136.83497619628906\n","Error at Step 147: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 148, Loss: 98.86835479736328\n","Epoch 3, Step 149, Loss: 114.54955291748047\n","Epoch 3, Step 150, Loss: 93.34098815917969\n","Error at Step 151: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 152, Loss: 104.32127380371094\n","Epoch 3, Step 153, Loss: 129.12355041503906\n","Epoch 3, Step 154, Loss: 115.36920928955078\n","Error at Step 155: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 156, Loss: 119.12296295166016\n","Epoch 3, Step 157, Loss: 150.15914916992188\n","Epoch 3, Step 158, Loss: 95.82980346679688\n","Error at Step 159: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 160, Loss: 164.53030395507812\n","Epoch 3, Step 161, Loss: 115.72919464111328\n","Epoch 3, Step 162, Loss: 125.5263671875\n","Error at Step 163: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 164, Loss: 117.60993194580078\n","Epoch 3, Step 165, Loss: 147.8941650390625\n","Epoch 3, Step 166, Loss: 129.7640380859375\n","Error at Step 167: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 168, Loss: 147.6002197265625\n","Epoch 3, Step 169, Loss: 97.69694519042969\n","Epoch 3, Step 170, Loss: 115.17343139648438\n","Error at Step 171: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 172, Loss: 89.4912109375\n","Epoch 3, Step 173, Loss: 174.46041870117188\n","Epoch 3, Step 174, Loss: 127.45965576171875\n","Error at Step 175: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 176, Loss: 143.10055541992188\n","Epoch 3, Step 177, Loss: 231.5989532470703\n","Epoch 3, Step 178, Loss: 92.03721618652344\n","Error at Step 179: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 180, Loss: 135.5286102294922\n","Epoch 3, Step 181, Loss: 140.27450561523438\n","Epoch 3, Step 182, Loss: 108.31332397460938\n","Error at Step 183: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 184, Loss: 128.38653564453125\n","Epoch 3, Step 185, Loss: 203.01112365722656\n","Epoch 3, Step 186, Loss: 175.89483642578125\n","Error at Step 187: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 188, Loss: 172.5526885986328\n","Epoch 3, Step 189, Loss: 87.85291290283203\n","Epoch 3, Step 190, Loss: 138.53387451171875\n","Error at Step 191: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 192, Loss: 99.99732971191406\n","Epoch 3, Step 193, Loss: 124.27120971679688\n","Epoch 3, Step 194, Loss: 211.9744110107422\n","Error at Step 195: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 196, Loss: 127.88494110107422\n","Epoch 3, Step 197, Loss: 107.7485580444336\n","Epoch 3, Step 198, Loss: 88.70372772216797\n","Error at Step 199: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 200, Loss: 99.59303283691406\n","Epoch 3, Step 201, Loss: 117.88658905029297\n","Epoch 3, Step 202, Loss: 137.8919677734375\n","Error at Step 203: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 204, Loss: 116.13982391357422\n","Epoch 3, Step 205, Loss: 126.50350952148438\n","Epoch 3, Step 206, Loss: 136.2218780517578\n","Error at Step 207: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 208, Loss: 132.9066925048828\n","Epoch 3, Step 209, Loss: 83.68836975097656\n","Epoch 3, Step 210, Loss: 114.83250427246094\n","Error at Step 211: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 212, Loss: 124.96148681640625\n","Epoch 3, Step 213, Loss: 133.81700134277344\n","Epoch 3, Step 214, Loss: 90.51111602783203\n","Error at Step 215: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 216, Loss: 102.97059631347656\n","Epoch 3, Step 217, Loss: 105.04691314697266\n","Epoch 3, Step 218, Loss: 88.40653991699219\n","Error at Step 219: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 220, Loss: 129.83743286132812\n","Epoch 3, Step 221, Loss: 152.0289306640625\n","Epoch 3, Step 222, Loss: 141.08969116210938\n","Error at Step 223: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 224, Loss: 145.4708251953125\n","Epoch 3, Step 225, Loss: 123.50865173339844\n","Epoch 3, Step 226, Loss: 102.02713012695312\n","Error at Step 227: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 228, Loss: 115.73274230957031\n","Epoch 3, Step 229, Loss: 114.68046569824219\n","Epoch 3, Step 230, Loss: 114.05561828613281\n","Error at Step 231: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 232, Loss: 128.48300170898438\n","Epoch 3, Step 233, Loss: 117.62884521484375\n","Epoch 3, Step 234, Loss: 172.5870361328125\n","Error at Step 235: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 236, Loss: 128.06781005859375\n","Epoch 3, Step 237, Loss: 101.39310455322266\n","Epoch 3, Step 238, Loss: 115.2208251953125\n","Error at Step 239: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 240, Loss: 148.28916931152344\n","Epoch 3, Step 241, Loss: 143.9317169189453\n","Epoch 3, Step 242, Loss: 137.32118225097656\n","Error at Step 243: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 244, Loss: 121.8855972290039\n","Epoch 3, Step 245, Loss: 133.88885498046875\n","Epoch 3, Step 246, Loss: 145.6063690185547\n","Error at Step 247: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 248, Loss: 95.96528625488281\n","Epoch 3, Step 249, Loss: 217.3908233642578\n","Epoch 3, Step 250, Loss: 102.8560791015625\n","Error at Step 251: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 252, Loss: 229.41790771484375\n","Epoch 3, Step 253, Loss: 123.76466369628906\n","Epoch 3, Step 254, Loss: 155.6302490234375\n","Error at Step 255: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 256, Loss: 83.31571960449219\n","Epoch 3, Step 257, Loss: 102.24818420410156\n","Epoch 3, Step 258, Loss: 124.2584228515625\n","Error at Step 259: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 260, Loss: 221.96652221679688\n","Epoch 3, Step 261, Loss: 121.45364379882812\n","Epoch 3, Step 262, Loss: 130.45404052734375\n","Error at Step 263: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 264, Loss: 94.0763931274414\n","Epoch 3, Step 265, Loss: 93.83747100830078\n","Epoch 3, Step 266, Loss: 133.51390075683594\n","Error at Step 267: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 268, Loss: 129.1604766845703\n","Epoch 3, Step 269, Loss: 104.16677856445312\n","Epoch 3, Step 270, Loss: 125.8380126953125\n","Error at Step 271: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 272, Loss: 151.1470184326172\n","Epoch 3, Step 273, Loss: 108.64665222167969\n","Epoch 3, Step 274, Loss: 145.67916870117188\n","Error at Step 275: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 276, Loss: 108.530029296875\n","Epoch 3, Step 277, Loss: 150.685791015625\n","Epoch 3, Step 278, Loss: 191.0002899169922\n","Error at Step 279: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 280, Loss: 122.05823516845703\n","Epoch 3, Step 281, Loss: 84.87054443359375\n","Epoch 3, Step 282, Loss: 220.19168090820312\n","Error at Step 283: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 284, Loss: 106.06501007080078\n","Epoch 3, Step 285, Loss: 100.1007080078125\n","Epoch 3, Step 286, Loss: 97.20372772216797\n","Error at Step 287: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 288, Loss: 174.3536834716797\n","Epoch 3, Step 289, Loss: 105.12342071533203\n","Epoch 3, Step 290, Loss: 149.36392211914062\n","Error at Step 291: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 292, Loss: 113.61138153076172\n","Epoch 3, Step 293, Loss: 102.42915344238281\n","Epoch 3, Step 294, Loss: 104.15179443359375\n","Error at Step 295: Attempting to unscale FP16 gradients.\n","Epoch 3, Step 296, Loss: 170.31536865234375\n","Epoch 3, Step 297, Loss: 92.38934326171875\n","Epoch 3, Step 298, Loss: 125.89679718017578\n","Error at Step 299: Attempting to unscale FP16 gradients.\n","Starting epoch 4/5\n","Epoch 4, Step 0, Loss: 90.41777801513672\n","Epoch 4, Step 1, Loss: 133.8653564453125\n","Epoch 4, Step 2, Loss: 154.2357177734375\n","Error at Step 3: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 4, Loss: 231.8559112548828\n","Epoch 4, Step 5, Loss: 102.15619659423828\n","Epoch 4, Step 6, Loss: 104.88430786132812\n","Error at Step 7: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 8, Loss: 95.94024658203125\n","Epoch 4, Step 9, Loss: 153.859619140625\n","Epoch 4, Step 10, Loss: 90.2275161743164\n","Error at Step 11: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 12, Loss: 106.2774658203125\n","Epoch 4, Step 13, Loss: 132.1208038330078\n","Epoch 4, Step 14, Loss: 124.57839965820312\n","Error at Step 15: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 16, Loss: 133.38088989257812\n","Epoch 4, Step 17, Loss: 99.84132385253906\n","Epoch 4, Step 18, Loss: 140.28787231445312\n","Error at Step 19: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 20, Loss: 99.52902221679688\n","Epoch 4, Step 21, Loss: 110.7005386352539\n","Epoch 4, Step 22, Loss: 197.07781982421875\n","Error at Step 23: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 24, Loss: 191.07835388183594\n","Epoch 4, Step 25, Loss: 87.81476593017578\n","Epoch 4, Step 26, Loss: 89.54700469970703\n","Error at Step 27: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 28, Loss: 114.60757446289062\n","Epoch 4, Step 29, Loss: 157.67872619628906\n","Epoch 4, Step 30, Loss: 132.84434509277344\n","Error at Step 31: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 32, Loss: 124.93576049804688\n","Epoch 4, Step 33, Loss: 115.36690521240234\n","Epoch 4, Step 34, Loss: 99.13095092773438\n","Error at Step 35: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 36, Loss: 121.81031799316406\n","Epoch 4, Step 37, Loss: 115.9440689086914\n","Epoch 4, Step 38, Loss: 100.29617309570312\n","Error at Step 39: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 40, Loss: 119.85398864746094\n","Epoch 4, Step 41, Loss: 156.61373901367188\n","Epoch 4, Step 42, Loss: 128.1484375\n","Error at Step 43: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 44, Loss: 137.81944274902344\n","Epoch 4, Step 45, Loss: 162.8162078857422\n","Epoch 4, Step 46, Loss: 88.68102264404297\n","Error at Step 47: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 48, Loss: 115.69548797607422\n","Epoch 4, Step 49, Loss: 194.49270629882812\n","Epoch 4, Step 50, Loss: 128.860595703125\n","Error at Step 51: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 52, Loss: 132.0639190673828\n","Epoch 4, Step 53, Loss: 119.05323028564453\n","Epoch 4, Step 54, Loss: 118.45074462890625\n","Error at Step 55: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 56, Loss: 115.86104583740234\n","Epoch 4, Step 57, Loss: 96.57831573486328\n","Epoch 4, Step 58, Loss: 131.04013061523438\n","Error at Step 59: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 60, Loss: 125.85237884521484\n","Epoch 4, Step 61, Loss: 147.99368286132812\n","Epoch 4, Step 62, Loss: 134.81053161621094\n","Error at Step 63: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 64, Loss: 157.3066864013672\n","Epoch 4, Step 65, Loss: 151.1497344970703\n","Epoch 4, Step 66, Loss: 298.3321838378906\n","Error at Step 67: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 68, Loss: 104.61441040039062\n","Epoch 4, Step 69, Loss: 161.73184204101562\n","Epoch 4, Step 70, Loss: 86.30488586425781\n","Error at Step 71: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 72, Loss: 145.52777099609375\n","Epoch 4, Step 73, Loss: 248.55848693847656\n","Epoch 4, Step 74, Loss: 123.9861831665039\n","Error at Step 75: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 76, Loss: 123.67477416992188\n","Epoch 4, Step 77, Loss: 170.21945190429688\n","Epoch 4, Step 78, Loss: 137.89541625976562\n","Error at Step 79: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 80, Loss: 125.53811645507812\n","Epoch 4, Step 81, Loss: 102.76660919189453\n","Epoch 4, Step 82, Loss: 158.24734497070312\n","Error at Step 83: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 84, Loss: 174.67686462402344\n","Epoch 4, Step 85, Loss: 117.59943389892578\n","Epoch 4, Step 86, Loss: 229.4573516845703\n","Error at Step 87: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 88, Loss: 98.16400909423828\n","Epoch 4, Step 89, Loss: 137.8533935546875\n","Epoch 4, Step 90, Loss: 122.62899017333984\n","Error at Step 91: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 92, Loss: 92.20440673828125\n","Epoch 4, Step 93, Loss: 127.62284088134766\n","Epoch 4, Step 94, Loss: 106.12939453125\n","Error at Step 95: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 96, Loss: 129.00633239746094\n","Epoch 4, Step 97, Loss: 170.42694091796875\n","Epoch 4, Step 98, Loss: 106.73417663574219\n","Error at Step 99: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 100, Loss: 101.75756072998047\n","Epoch 4, Step 101, Loss: 152.83407592773438\n","Epoch 4, Step 102, Loss: 133.92942810058594\n","Error at Step 103: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 104, Loss: 111.2538070678711\n","Epoch 4, Step 105, Loss: 152.1124725341797\n","Epoch 4, Step 106, Loss: 165.56393432617188\n","Error at Step 107: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 108, Loss: 148.0669708251953\n","Epoch 4, Step 109, Loss: 132.7620849609375\n","Epoch 4, Step 110, Loss: 164.20919799804688\n","Error at Step 111: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 112, Loss: 80.52281951904297\n","Epoch 4, Step 113, Loss: 123.55158996582031\n","Epoch 4, Step 114, Loss: 118.92273712158203\n","Error at Step 115: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 116, Loss: 143.21759033203125\n","Epoch 4, Step 117, Loss: 108.4699935913086\n","Epoch 4, Step 118, Loss: 92.05440521240234\n","Error at Step 119: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 120, Loss: 175.73782348632812\n","Epoch 4, Step 121, Loss: 106.04322052001953\n","Epoch 4, Step 122, Loss: 124.22949981689453\n","Error at Step 123: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 124, Loss: 172.5186767578125\n","Epoch 4, Step 125, Loss: 116.97824096679688\n","Epoch 4, Step 126, Loss: 102.9740982055664\n","Error at Step 127: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 128, Loss: 88.31544494628906\n","Epoch 4, Step 129, Loss: 125.97404479980469\n","Epoch 4, Step 130, Loss: 79.28519439697266\n","Error at Step 131: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 132, Loss: 120.01818084716797\n","Epoch 4, Step 133, Loss: 186.1529998779297\n","Epoch 4, Step 134, Loss: 108.99689483642578\n","Error at Step 135: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 136, Loss: 101.43143463134766\n","Epoch 4, Step 137, Loss: 95.45682525634766\n","Epoch 4, Step 138, Loss: 115.38346862792969\n","Error at Step 139: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 140, Loss: 136.50070190429688\n","Epoch 4, Step 141, Loss: 108.32618713378906\n","Epoch 4, Step 142, Loss: 120.03396606445312\n","Error at Step 143: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 144, Loss: 114.0660171508789\n","Epoch 4, Step 145, Loss: 104.70841217041016\n","Epoch 4, Step 146, Loss: 128.36227416992188\n","Error at Step 147: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 148, Loss: 112.5301742553711\n","Epoch 4, Step 149, Loss: 114.82856750488281\n","Epoch 4, Step 150, Loss: 170.5542449951172\n","Error at Step 151: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 152, Loss: 96.70134735107422\n","Epoch 4, Step 153, Loss: 139.60714721679688\n","Epoch 4, Step 154, Loss: 142.91055297851562\n","Error at Step 155: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 156, Loss: 131.18441772460938\n","Epoch 4, Step 157, Loss: 114.80992126464844\n","Epoch 4, Step 158, Loss: 101.3047866821289\n","Error at Step 159: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 160, Loss: 120.80509185791016\n","Epoch 4, Step 161, Loss: 83.21363830566406\n","Epoch 4, Step 162, Loss: 143.1037139892578\n","Error at Step 163: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 164, Loss: 133.63131713867188\n","Epoch 4, Step 165, Loss: 117.7396240234375\n","Epoch 4, Step 166, Loss: 196.81051635742188\n","Error at Step 167: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 168, Loss: 87.00315856933594\n","Epoch 4, Step 169, Loss: 145.0617218017578\n","Epoch 4, Step 170, Loss: 104.48880004882812\n","Error at Step 171: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 172, Loss: 84.63285827636719\n","Epoch 4, Step 173, Loss: 145.63475036621094\n","Epoch 4, Step 174, Loss: 124.46485137939453\n","Error at Step 175: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 176, Loss: 101.39954376220703\n","Epoch 4, Step 177, Loss: 121.89300537109375\n","Epoch 4, Step 178, Loss: 111.40570831298828\n","Error at Step 179: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 180, Loss: 168.1436004638672\n","Epoch 4, Step 181, Loss: 222.05484008789062\n","Epoch 4, Step 182, Loss: 129.7533721923828\n","Error at Step 183: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 184, Loss: 92.20529174804688\n","Epoch 4, Step 185, Loss: 102.76276397705078\n","Epoch 4, Step 186, Loss: 93.82369995117188\n","Error at Step 187: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 188, Loss: 107.7059555053711\n","Epoch 4, Step 189, Loss: 83.82990264892578\n","Epoch 4, Step 190, Loss: 117.27963256835938\n","Error at Step 191: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 192, Loss: 113.1560287475586\n","Epoch 4, Step 193, Loss: 97.43978118896484\n","Epoch 4, Step 194, Loss: 142.79629516601562\n","Error at Step 195: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 196, Loss: 147.79336547851562\n","Epoch 4, Step 197, Loss: 99.9166030883789\n","Epoch 4, Step 198, Loss: 104.13192749023438\n","Error at Step 199: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 200, Loss: 214.8771514892578\n","Epoch 4, Step 201, Loss: 108.48418426513672\n","Epoch 4, Step 202, Loss: 134.43287658691406\n","Error at Step 203: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 204, Loss: 114.837890625\n","Epoch 4, Step 205, Loss: 143.39915466308594\n","Epoch 4, Step 206, Loss: 142.87586975097656\n","Error at Step 207: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 208, Loss: 150.60830688476562\n","Epoch 4, Step 209, Loss: 121.47860717773438\n","Epoch 4, Step 210, Loss: 158.95420837402344\n","Error at Step 211: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 212, Loss: 144.0028839111328\n","Epoch 4, Step 213, Loss: 128.5288543701172\n","Epoch 4, Step 214, Loss: 114.72331237792969\n","Error at Step 215: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 216, Loss: 121.85926818847656\n","Epoch 4, Step 217, Loss: 103.77391052246094\n","Epoch 4, Step 218, Loss: 185.75439453125\n","Error at Step 219: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 220, Loss: 105.08961486816406\n","Epoch 4, Step 221, Loss: 119.08226776123047\n","Epoch 4, Step 222, Loss: 133.97508239746094\n","Error at Step 223: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 224, Loss: 147.89694213867188\n","Epoch 4, Step 225, Loss: 146.2756805419922\n","Epoch 4, Step 226, Loss: 128.5094451904297\n","Error at Step 227: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 228, Loss: 111.94557189941406\n","Epoch 4, Step 229, Loss: 108.71438598632812\n","Epoch 4, Step 230, Loss: 156.0414581298828\n","Error at Step 231: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 232, Loss: 159.2129669189453\n","Epoch 4, Step 233, Loss: 184.13323974609375\n","Epoch 4, Step 234, Loss: 133.2146453857422\n","Error at Step 235: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 236, Loss: 132.5408477783203\n","Epoch 4, Step 237, Loss: 84.96631622314453\n","Epoch 4, Step 238, Loss: 155.73037719726562\n","Error at Step 239: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 240, Loss: 102.42298889160156\n","Epoch 4, Step 241, Loss: 133.7849578857422\n","Epoch 4, Step 242, Loss: 119.52874755859375\n","Error at Step 243: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 244, Loss: 129.24661254882812\n","Epoch 4, Step 245, Loss: 118.14128112792969\n","Epoch 4, Step 246, Loss: 114.6091537475586\n","Error at Step 247: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 248, Loss: 123.84577178955078\n","Epoch 4, Step 249, Loss: 164.59664916992188\n","Epoch 4, Step 250, Loss: 93.7431869506836\n","Error at Step 251: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 252, Loss: 148.4439239501953\n","Epoch 4, Step 253, Loss: 113.31245422363281\n","Epoch 4, Step 254, Loss: 90.34575653076172\n","Error at Step 255: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 256, Loss: 120.414794921875\n","Epoch 4, Step 257, Loss: 144.3741912841797\n","Epoch 4, Step 258, Loss: 174.25341796875\n","Error at Step 259: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 260, Loss: 122.02233123779297\n","Epoch 4, Step 261, Loss: 108.40866088867188\n","Epoch 4, Step 262, Loss: 199.2503662109375\n","Error at Step 263: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 264, Loss: 121.42196655273438\n","Epoch 4, Step 265, Loss: 156.1983642578125\n","Epoch 4, Step 266, Loss: 168.75335693359375\n","Error at Step 267: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 268, Loss: 105.15433502197266\n","Epoch 4, Step 269, Loss: 108.96780395507812\n","Epoch 4, Step 270, Loss: 97.14708709716797\n","Error at Step 271: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 272, Loss: 107.89443969726562\n","Epoch 4, Step 273, Loss: 109.90665435791016\n","Epoch 4, Step 274, Loss: 137.5217742919922\n","Error at Step 275: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 276, Loss: 112.98535919189453\n","Epoch 4, Step 277, Loss: 113.62306213378906\n","Epoch 4, Step 278, Loss: 105.53874969482422\n","Error at Step 279: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 280, Loss: 117.9404296875\n","Epoch 4, Step 281, Loss: 138.067138671875\n","Epoch 4, Step 282, Loss: 113.37400817871094\n","Error at Step 283: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 284, Loss: 136.4515838623047\n","Epoch 4, Step 285, Loss: 101.87235260009766\n","Epoch 4, Step 286, Loss: 127.82963562011719\n","Error at Step 287: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 288, Loss: 210.19390869140625\n","Epoch 4, Step 289, Loss: 93.29216766357422\n","Epoch 4, Step 290, Loss: 103.62703704833984\n","Error at Step 291: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 292, Loss: 75.11820220947266\n","Epoch 4, Step 293, Loss: 115.08381652832031\n","Epoch 4, Step 294, Loss: 129.7813262939453\n","Error at Step 295: Attempting to unscale FP16 gradients.\n","Epoch 4, Step 296, Loss: 100.88714599609375\n","Epoch 4, Step 297, Loss: 169.5693817138672\n","Epoch 4, Step 298, Loss: 220.21470642089844\n","Error at Step 299: Attempting to unscale FP16 gradients.\n","Starting epoch 5/5\n","Epoch 5, Step 0, Loss: 122.71337890625\n","Epoch 5, Step 1, Loss: 101.73001098632812\n","Epoch 5, Step 2, Loss: 101.94453430175781\n","Error at Step 3: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 4, Loss: 157.34483337402344\n","Epoch 5, Step 5, Loss: 196.87814331054688\n","Epoch 5, Step 6, Loss: 104.98186492919922\n","Error at Step 7: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 8, Loss: 110.61749267578125\n","Epoch 5, Step 9, Loss: 121.70573425292969\n","Epoch 5, Step 10, Loss: 87.93867492675781\n","Error at Step 11: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 12, Loss: 118.45843505859375\n","Epoch 5, Step 13, Loss: 133.86473083496094\n","Epoch 5, Step 14, Loss: 102.4141616821289\n","Error at Step 15: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 16, Loss: 137.97705078125\n","Epoch 5, Step 17, Loss: 103.0304183959961\n","Epoch 5, Step 18, Loss: 119.99188995361328\n","Error at Step 19: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 20, Loss: 79.50869750976562\n","Epoch 5, Step 21, Loss: 88.34268951416016\n","Epoch 5, Step 22, Loss: 90.53228759765625\n","Error at Step 23: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 24, Loss: 83.22378540039062\n","Epoch 5, Step 25, Loss: 115.31153106689453\n","Epoch 5, Step 26, Loss: 150.3465576171875\n","Error at Step 27: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 28, Loss: 128.61474609375\n","Epoch 5, Step 29, Loss: 159.02996826171875\n","Epoch 5, Step 30, Loss: 157.95217895507812\n","Error at Step 31: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 32, Loss: 129.16156005859375\n","Epoch 5, Step 33, Loss: 159.754150390625\n","Epoch 5, Step 34, Loss: 107.94190216064453\n","Error at Step 35: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 36, Loss: 210.35556030273438\n","Epoch 5, Step 37, Loss: 113.6835708618164\n","Epoch 5, Step 38, Loss: 205.97972106933594\n","Error at Step 39: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 40, Loss: 152.28985595703125\n","Epoch 5, Step 41, Loss: 108.91117095947266\n","Epoch 5, Step 42, Loss: 132.62033081054688\n","Error at Step 43: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 44, Loss: 168.93702697753906\n","Epoch 5, Step 45, Loss: 128.9127655029297\n","Epoch 5, Step 46, Loss: 104.30792999267578\n","Error at Step 47: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 48, Loss: 98.07545471191406\n","Epoch 5, Step 49, Loss: 108.92668151855469\n","Epoch 5, Step 50, Loss: 116.3442153930664\n","Error at Step 51: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 52, Loss: 197.14077758789062\n","Epoch 5, Step 53, Loss: 145.552001953125\n","Epoch 5, Step 54, Loss: 116.02196502685547\n","Error at Step 55: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 56, Loss: 143.12319946289062\n","Epoch 5, Step 57, Loss: 142.82676696777344\n","Epoch 5, Step 58, Loss: 170.57666015625\n","Error at Step 59: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 60, Loss: 95.95401000976562\n","Epoch 5, Step 61, Loss: 144.53488159179688\n","Epoch 5, Step 62, Loss: 155.61607360839844\n","Error at Step 63: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 64, Loss: 169.5069122314453\n","Epoch 5, Step 65, Loss: 121.7451400756836\n","Epoch 5, Step 66, Loss: 109.98596954345703\n","Error at Step 67: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 68, Loss: 185.96261596679688\n","Epoch 5, Step 69, Loss: 100.27234649658203\n","Epoch 5, Step 70, Loss: 112.85693359375\n","Error at Step 71: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 72, Loss: 133.70547485351562\n","Epoch 5, Step 73, Loss: 133.60585021972656\n","Epoch 5, Step 74, Loss: 136.56797790527344\n","Error at Step 75: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 76, Loss: 145.50509643554688\n","Epoch 5, Step 77, Loss: 132.10110473632812\n","Epoch 5, Step 78, Loss: 113.25357055664062\n","Error at Step 79: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 80, Loss: 100.07852172851562\n","Epoch 5, Step 81, Loss: 123.67179870605469\n","Epoch 5, Step 82, Loss: 141.09080505371094\n","Error at Step 83: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 84, Loss: 149.0413818359375\n","Epoch 5, Step 85, Loss: 231.7985076904297\n","Epoch 5, Step 86, Loss: 107.32323455810547\n","Error at Step 87: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 88, Loss: 137.88539123535156\n","Epoch 5, Step 89, Loss: 155.82652282714844\n","Epoch 5, Step 90, Loss: 199.27626037597656\n","Error at Step 91: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 92, Loss: 114.53160095214844\n","Epoch 5, Step 93, Loss: 130.01693725585938\n","Epoch 5, Step 94, Loss: 128.04400634765625\n","Error at Step 95: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 96, Loss: 148.45733642578125\n","Epoch 5, Step 97, Loss: 163.97311401367188\n","Epoch 5, Step 98, Loss: 111.96572875976562\n","Error at Step 99: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 100, Loss: 170.34765625\n","Epoch 5, Step 101, Loss: 128.39012145996094\n","Epoch 5, Step 102, Loss: 117.77015686035156\n","Error at Step 103: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 104, Loss: 174.51351928710938\n","Epoch 5, Step 105, Loss: 129.85157775878906\n","Epoch 5, Step 106, Loss: 143.0938262939453\n","Error at Step 107: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 108, Loss: 102.255126953125\n","Epoch 5, Step 109, Loss: 119.55989074707031\n","Epoch 5, Step 110, Loss: 138.74871826171875\n","Error at Step 111: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 112, Loss: 96.93013763427734\n","Epoch 5, Step 113, Loss: 124.45594024658203\n","Epoch 5, Step 114, Loss: 137.87977600097656\n","Error at Step 115: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 116, Loss: 117.15040588378906\n","Epoch 5, Step 117, Loss: 175.77528381347656\n","Epoch 5, Step 118, Loss: 92.28369903564453\n","Error at Step 119: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 120, Loss: 102.8601303100586\n","Epoch 5, Step 121, Loss: 119.87150573730469\n","Epoch 5, Step 122, Loss: 229.39865112304688\n","Error at Step 123: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 124, Loss: 104.3927001953125\n","Epoch 5, Step 125, Loss: 118.13267517089844\n","Epoch 5, Step 126, Loss: 132.10797119140625\n","Error at Step 127: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 128, Loss: 137.86813354492188\n","Epoch 5, Step 129, Loss: 162.88995361328125\n","Epoch 5, Step 130, Loss: 118.99756622314453\n","Error at Step 131: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 132, Loss: 88.80486297607422\n","Epoch 5, Step 133, Loss: 108.57621002197266\n","Epoch 5, Step 134, Loss: 92.3043212890625\n","Error at Step 135: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 136, Loss: 97.31945037841797\n","Epoch 5, Step 137, Loss: 119.9404067993164\n","Epoch 5, Step 138, Loss: 90.42173767089844\n","Error at Step 139: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 140, Loss: 93.95201873779297\n","Epoch 5, Step 141, Loss: 106.03068542480469\n","Epoch 5, Step 142, Loss: 184.24346923828125\n","Error at Step 143: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 144, Loss: 99.93325805664062\n","Epoch 5, Step 145, Loss: 105.8169174194336\n","Epoch 5, Step 146, Loss: 121.905517578125\n","Error at Step 147: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 148, Loss: 99.32576751708984\n","Epoch 5, Step 149, Loss: 134.12387084960938\n","Epoch 5, Step 150, Loss: 86.14834594726562\n","Error at Step 151: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 152, Loss: 102.68701171875\n","Epoch 5, Step 153, Loss: 102.43878936767578\n","Epoch 5, Step 154, Loss: 222.14805603027344\n","Error at Step 155: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 156, Loss: 145.6269989013672\n","Epoch 5, Step 157, Loss: 124.77476501464844\n","Epoch 5, Step 158, Loss: 106.42955017089844\n","Error at Step 159: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 160, Loss: 101.50028991699219\n","Epoch 5, Step 161, Loss: 139.7320556640625\n","Epoch 5, Step 162, Loss: 127.56289672851562\n","Error at Step 163: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 164, Loss: 135.69482421875\n","Epoch 5, Step 165, Loss: 107.7970199584961\n","Epoch 5, Step 166, Loss: 186.0061492919922\n","Error at Step 167: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 168, Loss: 168.2378692626953\n","Epoch 5, Step 169, Loss: 152.14134216308594\n","Epoch 5, Step 170, Loss: 108.125\n","Error at Step 171: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 172, Loss: 156.15127563476562\n","Epoch 5, Step 173, Loss: 80.51103210449219\n","Epoch 5, Step 174, Loss: 105.20735931396484\n","Error at Step 175: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 176, Loss: 126.12347412109375\n","Epoch 5, Step 177, Loss: 106.20895385742188\n","Epoch 5, Step 178, Loss: 118.88774871826172\n","Error at Step 179: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 180, Loss: 130.45843505859375\n","Epoch 5, Step 181, Loss: 186.9671630859375\n","Epoch 5, Step 182, Loss: 122.74625396728516\n","Error at Step 183: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 184, Loss: 99.6412582397461\n","Epoch 5, Step 185, Loss: 156.36785888671875\n","Epoch 5, Step 186, Loss: 117.5726089477539\n","Error at Step 187: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 188, Loss: 108.14288330078125\n","Epoch 5, Step 189, Loss: 128.88111877441406\n","Epoch 5, Step 190, Loss: 194.3037567138672\n","Error at Step 191: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 192, Loss: 97.22679901123047\n","Epoch 5, Step 193, Loss: 136.5753631591797\n","Epoch 5, Step 194, Loss: 97.74188232421875\n","Error at Step 195: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 196, Loss: 152.86727905273438\n","Epoch 5, Step 197, Loss: 126.14474487304688\n","Epoch 5, Step 198, Loss: 102.09049224853516\n","Error at Step 199: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 200, Loss: 137.3180694580078\n","Epoch 5, Step 201, Loss: 106.684814453125\n","Epoch 5, Step 202, Loss: 164.70115661621094\n","Error at Step 203: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 204, Loss: 154.2030487060547\n","Epoch 5, Step 205, Loss: 103.69205474853516\n","Epoch 5, Step 206, Loss: 115.9198226928711\n","Error at Step 207: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 208, Loss: 105.62828063964844\n","Epoch 5, Step 209, Loss: 136.1044158935547\n","Epoch 5, Step 210, Loss: 121.9200439453125\n","Error at Step 211: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 212, Loss: 116.93814849853516\n","Epoch 5, Step 213, Loss: 124.3559799194336\n","Epoch 5, Step 214, Loss: 108.42675018310547\n","Error at Step 215: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 216, Loss: 133.73435974121094\n","Epoch 5, Step 217, Loss: 220.19815063476562\n","Epoch 5, Step 218, Loss: 143.7621307373047\n","Error at Step 219: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 220, Loss: 174.265380859375\n","Epoch 5, Step 221, Loss: 153.9415740966797\n","Epoch 5, Step 222, Loss: 75.16162872314453\n","Error at Step 223: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 224, Loss: 119.98370361328125\n","Epoch 5, Step 225, Loss: 95.42412567138672\n","Epoch 5, Step 226, Loss: 146.0080108642578\n","Error at Step 227: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 228, Loss: 103.76680755615234\n","Epoch 5, Step 229, Loss: 156.28042602539062\n","Epoch 5, Step 230, Loss: 127.49424743652344\n","Error at Step 231: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 232, Loss: 152.97760009765625\n","Epoch 5, Step 233, Loss: 86.96769714355469\n","Epoch 5, Step 234, Loss: 124.59859466552734\n","Error at Step 235: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 236, Loss: 135.5420379638672\n","Epoch 5, Step 237, Loss: 114.13235473632812\n","Epoch 5, Step 238, Loss: 113.79705047607422\n","Error at Step 239: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 240, Loss: 93.68619537353516\n","Epoch 5, Step 241, Loss: 114.87506866455078\n","Epoch 5, Step 242, Loss: 104.6412124633789\n","Error at Step 243: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 244, Loss: 120.62198638916016\n","Epoch 5, Step 245, Loss: 148.52880859375\n","Epoch 5, Step 246, Loss: 84.84095001220703\n","Error at Step 247: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 248, Loss: 98.13832092285156\n","Epoch 5, Step 249, Loss: 231.50025939941406\n","Epoch 5, Step 250, Loss: 92.2559814453125\n","Error at Step 251: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 252, Loss: 158.27645874023438\n","Epoch 5, Step 253, Loss: 133.2386474609375\n","Epoch 5, Step 254, Loss: 170.45358276367188\n","Error at Step 255: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 256, Loss: 124.03885650634766\n","Epoch 5, Step 257, Loss: 132.96795654296875\n","Epoch 5, Step 258, Loss: 97.95757293701172\n","Error at Step 259: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 260, Loss: 248.5520477294922\n","Epoch 5, Step 261, Loss: 115.84300994873047\n","Epoch 5, Step 262, Loss: 101.51162719726562\n","Error at Step 263: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 264, Loss: 134.88536071777344\n","Epoch 5, Step 265, Loss: 117.8707504272461\n","Epoch 5, Step 266, Loss: 100.33683776855469\n","Error at Step 267: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 268, Loss: 172.69142150878906\n","Epoch 5, Step 269, Loss: 113.93829345703125\n","Epoch 5, Step 270, Loss: 143.24588012695312\n","Error at Step 271: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 272, Loss: 92.2669448852539\n","Epoch 5, Step 273, Loss: 101.47046661376953\n","Epoch 5, Step 274, Loss: 108.9773941040039\n","Error at Step 275: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 276, Loss: 115.3687515258789\n","Epoch 5, Step 277, Loss: 101.15192413330078\n","Epoch 5, Step 278, Loss: 83.82410430908203\n","Error at Step 279: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 280, Loss: 114.67178344726562\n","Epoch 5, Step 281, Loss: 108.4287109375\n","Epoch 5, Step 282, Loss: 147.70730590820312\n","Error at Step 283: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 284, Loss: 102.32340240478516\n","Epoch 5, Step 285, Loss: 144.98915100097656\n","Epoch 5, Step 286, Loss: 115.22383117675781\n","Error at Step 287: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 288, Loss: 119.4138412475586\n","Epoch 5, Step 289, Loss: 101.755615234375\n","Epoch 5, Step 290, Loss: 150.64723205566406\n","Error at Step 291: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 292, Loss: 104.36162567138672\n","Epoch 5, Step 293, Loss: 104.70032501220703\n","Epoch 5, Step 294, Loss: 133.3946075439453\n","Error at Step 295: Attempting to unscale FP16 gradients.\n","Epoch 5, Step 296, Loss: 97.08335876464844\n","Epoch 5, Step 297, Loss: 114.58769989013672\n","Epoch 5, Step 298, Loss: 114.98082733154297\n","Error at Step 299: Attempting to unscale FP16 gradients.\n","Fine-tuning complete.\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","import json\n","from diffusers import StableDiffusionPipeline, DDPMScheduler\n","from diffusers.optimization import get_scheduler\n","from transformers import CLIPTokenizer\n","import os\n","import gc\n","\n","# Paths to your data\n","image_folder = \"/content/drive/MyDrive/interior-Design\"\n","metadata_file = \"/content/drive/MyDrive/captions_metadata_updated_paths.json\"\n","\n","# Device configuration\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load metadata\n","with open(metadata_file, \"r\") as f:\n","    metadata = json.load(f)\n","\n","# Dataset class\n","class InteriorDesignDataset(Dataset):\n","    def __init__(self, image_folder, metadata, tokenizer, resolution=512):\n","        self.image_folder = image_folder\n","        self.metadata = metadata\n","        self.tokenizer = tokenizer\n","        self.resolution = resolution\n","        self.transform = transforms.Compose([\n","            transforms.Resize((resolution, resolution)),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n","        ])\n","\n","    def __len__(self):\n","        return len(self.metadata)\n","\n","    def __getitem__(self, idx):\n","        entry = self.metadata[idx]\n","        image_path = os.path.join(self.image_folder, entry[\"image_path\"])\n","        caption = entry[\"caption\"]\n","\n","        # Load and preprocess the image\n","        try:\n","            image = Image.open(image_path).convert(\"RGB\")\n","            image = self.transform(image)\n","        except Exception as e:\n","            print(f\"Error loading image {image_path}: {e}\")\n","            return None\n","\n","        # Tokenize caption\n","        text_inputs = self.tokenizer(\n","            caption,\n","            max_length=self.tokenizer.model_max_length,\n","            truncation=True,\n","            padding=\"max_length\",\n","            return_tensors=\"pt\"\n","        )\n","        return {\n","            \"pixel_values\": image,\n","            \"input_ids\": text_inputs.input_ids.squeeze()\n","        }\n","\n","# Tokenizer\n","tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch16\")\n","\n","# Create dataset and dataloader\n","dataset = InteriorDesignDataset(image_folder, metadata, tokenizer)\n","dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n","\n","# Load Stable Diffusion pipeline\n","pipeline = StableDiffusionPipeline.from_pretrained(\n","    \"runwayml/stable-diffusion-v1-5\",\n","    torch_dtype=torch.float16,  # Use float16 precision\n","    scheduler=DDPMScheduler.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"scheduler\")\n",").to(device)\n","\n","# Enable memory-efficient attention\n","pipeline.enable_xformers_memory_efficient_attention()\n","\n","# Freeze everything except the U-Net\n","pipeline.text_encoder.requires_grad_(False)\n","pipeline.vae.requires_grad_(False)\n","\n","# Set U-Net to training mode\n","pipeline.unet.train()\n","\n","# Optimizer\n","optimizer = torch.optim.AdamW(pipeline.unet.parameters(), lr=1e-6)\n","\n","# Scheduler\n","scheduler = get_scheduler(\"linear\", optimizer, num_warmup_steps=100, num_training_steps=len(dataloader) * 5)\n","\n","# Training loop with AMP\n","scaler = torch.cuda.amp.GradScaler()\n","gradient_accumulation_steps = 4\n","num_epochs = 5\n","\n","for epoch in range(num_epochs):\n","    print(f\"Starting epoch {epoch + 1}/{num_epochs}\")\n","    for step, batch in enumerate(dataloader):\n","        try:\n","            if batch is None:\n","                continue\n","\n","            pixel_values = batch[\"pixel_values\"].to(device, dtype=torch.float16)\n","            input_ids = batch[\"input_ids\"].to(device)\n","\n","            latents = pipeline.vae.encode(pixel_values).latent_dist.sample()\n","            latents = latents * pipeline.vae.config.scaling_factor\n","\n","            noise_factor = 0.1 + (0.9 * step / len(dataloader))  # Gradual noise scaling\n","            noise = torch.randn_like(latents) * noise_factor\n","            timesteps = torch.randint(0, pipeline.scheduler.config.num_train_timesteps, (1,), device=device).long()\n","            noisy_latents = pipeline.scheduler.add_noise(latents, noise, timesteps)\n","\n","            encoder_hidden_states = pipeline.text_encoder(input_ids)[0]\n","\n","            with torch.cuda.amp.autocast():\n","                noise_pred = pipeline.unet(noisy_latents, timesteps, encoder_hidden_states).sample\n","                loss = torch.nn.functional.mse_loss(noise_pred, noise)\n","                regularization = 0.01 * torch.sum(latents ** 2)\n","                loss = loss + regularization\n","\n","            if torch.isnan(loss) or torch.isinf(loss):\n","                print(f\"Skipping step {step} due to NaN/inf loss\")\n","                optimizer.zero_grad()\n","                continue\n","\n","            scaler.scale(loss).backward()\n","\n","            if (step + 1) % gradient_accumulation_steps == 0:\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","\n","            if step % 1 == 0:  # Log every step\n","                print(f\"Epoch {epoch + 1}, Step {step}, Loss: {loss.item()}\")\n","\n","        except Exception as e:\n","            print(f\"Error at Step {step}: {e}\")\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","    pipeline.save_pretrained(f\"/content/drive/MyDrive/finetuned_models/epoch_{epoch + 1}\")\n","\n","print(\"Fine-tuning complete.\")\n"]},{"cell_type":"code","source":["#!pip install -U xformers --index-url https://download.pytorch.org/whl/cu124"],"metadata":{"id":"yEUQvMHIE5bb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from diffusers import StableDiffusionPipeline\n","from PIL import Image\n","from torchvision import transforms\n","import torch\n","\n","# Load fine-tuned model\n","fine_tuned_model_path = \"/content/drive/MyDrive/finetuned_models/epoch_5\"\n","pipeline = StableDiffusionPipeline.from_pretrained(\n","    fine_tuned_model_path,\n","    torch_dtype=torch.float16\n",").to(\"cuda\")\n","\n","# Preprocess input image\n","input_image_path = \"/content/drive/MyDrive/images.jpeg\"\n","image = Image.open(input_image_path).convert(\"RGB\")\n","image_transform = transforms.Compose([\n","    transforms.Resize((512, 512)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5], [0.5])\n","])\n","input_tensor = image_transform(image).unsqueeze(0).to(\"cuda\")\n","\n","# Generate output\n","prompt = \"A beautiful industrial-style bathroom with modern fixtures\"\n","with torch.no_grad():\n","    generated_images = pipeline(prompt=prompt, guidance_scale=7.5, num_inference_steps=50)\n","    output_image = generated_images.images[0]\n","\n","# Save output\n","output_image.save(\"/content/drive/MyDrive/generated_image1.jpg\")\n","print(\"Generated image saved!\")\n"],"metadata":{"id":"3rv4amfOFLCY","colab":{"base_uri":"https://localhost:8080/","height":99,"referenced_widgets":["aebffdbba5324c86812d70f352d4e858","5e29476125914cb3a0e5aa56b9f64e33","1bb7461152d440ddba7f9cf7fd2a8392","2f26d4208517497c92e3a61f16a53c9c","7c20fa41ed9e4e2e8b33f1ab98261559","baa6d0049e3b440e83e686d5931d1639","b161cc2939cf457198b5ead4011fa9fd","a54adea02bb546299087055cf6480a68","c27910b463184443ab46cdd9904ae535","3e3845a0ee22414cb93528bc49c77aa2","836d7a29f5bd4983baa5cb70651736cb","c67a1459d1cb487e8c6e0c941fa2b7db","294bb07e81974b35922ff62c422d7b05","a001f4588e1f4bcf8a0f0c1e0c4a9814","3f277120ccce4d0fb4357c20e10d2c4f","e7127823b33442f190469ba70caf584d","afa66bc7739b449cb32d770749ac1802","23165559d7e44deb82e558d515053dc0","9ffd02006fb648b2bbce11f0919d87d2","e023b920cbae473598dca4cef96bf6e9","dd82fafb7d0944ef977c27ba8f676de0","b69771876a564045928ffb1606e0b221"]},"executionInfo":{"status":"ok","timestamp":1737202579285,"user_tz":-330,"elapsed":27034,"user":{"displayName":"sumit sartale","userId":"13643088278365937465"}},"outputId":"9514035c-fa50-488f-fcce-47f30344f79a"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aebffdbba5324c86812d70f352d4e858"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c67a1459d1cb487e8c6e0c941fa2b7db"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Generated image saved!\n"]}]}]}